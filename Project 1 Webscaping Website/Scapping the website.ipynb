{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEBSCAPING WEBSITE https://keithgalli.github.io/web-scraping/webpage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://keithgalli.github.io/web-scraping/webpage.html')\n",
    "wp = bs(r.content)\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing all the Social links from the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are all the links not social links\n",
    "\n",
    "# import re\n",
    "# links = wp.select(\"a\") # wrong select doesnot have any thing like string etc  links = wp.select(\"a\", string = re.compile(\"www\"))\n",
    "# # for i in links:\n",
    "# #     print(i[\"href\"])\n",
    "# # print(links)\n",
    "# links = wp.find_all(\"a\", string = re.compile(\"www\"))\n",
    "# print(links)\n",
    "# for i in links:\n",
    "#     print(i[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using FIND\n",
    "\n",
    "social_links = wp.find(\"ul\" , attrs={\"class\":\"socials\"})\n",
    "# print(social_links)\n",
    "links = social_links.find_all(\"a\")\n",
    "# print(links)\n",
    "# actual_links= [link[\"href\"] for link in links]\n",
    "# print(actual_links)\n",
    "# for i in links:\n",
    "#     print(i[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  USING SELECT\n",
    "\n",
    "links = wp.select(\"ul.socials a\")\n",
    "# print(links)\n",
    "# for i in links:\n",
    "#     print(i['href'])\n",
    "actual_links = [link['href'] for link in links]\n",
    "# print(actual_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.instagram.com/keithgalli/', 'https://twitter.com/keithgalli', 'https://www.linkedin.com/in/keithgalli/', 'https://www.tiktok.com/@keithgalli']\n"
     ]
    }
   ],
   "source": [
    "## using select \n",
    "links = wp.select(\"li.social a\")\n",
    "# print(links)\n",
    "# for i in links:\n",
    "#     print(i['href'])\n",
    "act_links = [link['href'] for link in links]\n",
    "print(act_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text for tr in td]\n",
    "    l.append(row)\n",
    "pd.DataFrame(l, columns=[\"A\", \"B\", ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.dropna of          S                        Team    League  GP  G   A  TP PIM +/-  Â   \\\n",
       "0  2014-15  MIT (Mass. Inst. of Tech.)   ACHA II  17  3   9  12  20      |   \n",
       "1  2015-16  MIT (Mass. Inst. of Tech.)   ACHA II   9  1   1   2   2      |   \n",
       "2  2016-17  MIT (Mass. Inst. of Tech.)   ACHA II  12  5   5  10   8   0  |   \n",
       "3  2017-18                Did not play                                   |   \n",
       "4  2018-19  MIT (Mass. Inst. of Tech.)  ACHA III   8  5  10  15   8      |   \n",
       "\n",
       "  POST GP G A TP PIM +/-  \n",
       "0                         \n",
       "1                         \n",
       "2                         \n",
       "3                         \n",
       "4                         >"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table = wp.find(\"table\", attrs={\"class\":\"hockey-stats\"})\n",
    "# print(table)\n",
    "t_columns = table.find(\"thead\").find_all(\"th\")\n",
    "col_names= [n.string for n in t_columns]\n",
    "# print(col_names)\n",
    "\n",
    "table_rows = table.find('tbody').find_all('tr')\n",
    "# table_rows[0]\n",
    "l=[]\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [str(tr.get_text()).strip() for tr in td]    #str() method for converting to string and strip() for stripping the \\n' s\n",
    "    l.append(row)\n",
    "# print(l[0])\n",
    "df = pd.DataFrame(l, columns=col_names)\n",
    "df.head()\n",
    "# df['Team']\n",
    "# df.loc[df['Team']!='Did not play']\n",
    "df.dropna\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pandas already builtin fuction for reading a table\n",
    "# table = soup.find_all('table')\n",
    "# df = pd.read_html(str(table))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab All fun facts that uses word \"is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Middle name is Ronald', 'Dunkin Donuts coffee is better than Starbucks', \"A favorite book series of mine is Ender's Game\", 'Current video game of choice is Rocket League', \"The band that I've seen the most times live is the Zac Brown Band\"]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "facts = wp.select(\"ul.fun-facts li\")\n",
    "fact_with_is = [fact.find(string=re.compile(\"is\")) for fact in facts]\n",
    "# fact_with_is = [fact for fact in fact_with_is if fact]\n",
    "fact_with_is = [fact.find_parent().get_text() for fact in fact_with_is if fact]\n",
    "print(fact_with_is) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download The Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/italy/lake_como.jpg\n"
     ]
    }
   ],
   "source": [
    "url = \"https://keithgalli.github.io/web-scraping/\"\n",
    "images = wp.select(\"div.row div.column img\")\n",
    "img_url = images[0]['src']\n",
    "print(img_url)\n",
    "full_url = url+img_url\n",
    "\n",
    "img = requests.get(full_url).content\n",
    "with open('img1.jpg','wb') as handler:\n",
    "    handler.write(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Daunting code for extracting only the necessary images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./images/selfie1.jpg', 'images/italy/lake_como.jpg', 'images/italy/pontevecchio.jpg', 'images/italy/riomaggiore.jpg']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "images = wp.find_all(\"img\")\n",
    "# print(images)\n",
    "\n",
    "\n",
    "# print(images[0]['src'].get_text())\n",
    "\n",
    "# imgs = [image.find(\"src\", string=re.compile(\"images/flag.png\")) for image in images]\n",
    "# print(imgs)\n",
    "\n",
    "## For checking the presence of any string\n",
    "imgs = [image['src'] for image in images]\n",
    "# print(imgs)\n",
    "# if any('kyonbe' in s for s in imgs):\n",
    "#     print(True)\n",
    "# else:\n",
    "#     print(False)\n",
    "    \n",
    "## for Getting all the elements which do not contain the substring flags\n",
    "no_flag = [s for s in imgs if \"flag\" not in s]\n",
    "print(no_flag)\n",
    "    \n",
    "# for i in images:\n",
    "#     img_url= i['src']\n",
    "#     print(img_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating all Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://keithgalli.github.io/web-scraping/\"\n",
    "for i in no_flag:\n",
    "    img_url = i.replace(\"./\",\"\")\n",
    "    i_name= re.sub(\"[a-zA-Z]*/\",\"\",img_url)\n",
    "#     print(i_name)\n",
    "    full_url= url+img_url\n",
    "#     print(full_url)\n",
    "    img = requests.get(full_url).content\n",
    "    with open(i_name,'wb') as handler:\n",
    "        handler.write(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Mystery Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make\n",
      "sure\n",
      "to\n",
      "smash\n",
      "that\n",
      "like\n",
      "button\n",
      "and\n",
      "subscribe\n",
      "!!!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "files = wp.select(\"div.block a\")\n",
    "for f in files:\n",
    "#     print(f['href'])\n",
    "    file_url= f['href']\n",
    "    n_url = url + file_url\n",
    "#     print(n_url)\n",
    "    cont = requests.get(n_url)\n",
    "    data = bs(cont.content)\n",
    "#     print(cont)\n",
    "    sw = data.find(\"p\", attrs={\"id\":\"secret-word\"})\n",
    "    message = sw.string\n",
    "    print(message)\n",
    "#     if(sw != None):\n",
    "#         print(sw)\n",
    "#         print(f['href'])\n",
    "#         break\n",
    "\n",
    "    \n",
    "# links = [b.select(\"ul li a\") for b in blocks]  # instead u can directly access using select(div a)\n",
    "# print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
